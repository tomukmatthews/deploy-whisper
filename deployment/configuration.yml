# Load 3 Whisper models on the same GPU, any more and the competition for resources reduces throughput (a g5.xlarge A10)
runners:
 resources:
  nvidia.com/gpu: 1
 workers_per_resource: 3
